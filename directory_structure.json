{
    "run_demo.py": "import sys, os\n# Ensure the root project directory is in python path\nsys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), \"..\")))\n\nfrom project.main_agent import run_agent\n\nif __name__ == \"__main__\":\n    print(\"--- Running Demo ---\")\n    response = run_agent(\"Hello! This is a demo.\")\n    print(f\"Response: {response}\")\n",
    "tools": {
        "tools.py": "\"\"\"\nProvides data retrieval tools for the Worker agent.\n\"\"\"\nimport json\n\n# Static Data (Simulating JSON file load for simplicity)\nHELPLINES = {\n    \"US\": {\"name\": \"988 Suicide & Crisis Lifeline\", \"number\": \"988\"},\n    \"UK\": {\"name\": \"NHS 111\", \"number\": \"111\"},\n    \"IN\": {\"name\": \"Kiran Mental Health Helpline\", \"number\": \"1800-599-0019\"},\n    \"Global\": {\"name\": \"Befrienders Worldwide\", \"number\": \"Visit befrienders.org\"}\n}\n\nTECHNIQUES = {\n    \"box_breathing\": \"Inhale for 4 seconds, hold for 4 seconds, exhale for 4 seconds, hold for 4 seconds. Repeat.\",\n    \"54321_grounding\": \"Acknowledge 5 things you see, 4 you can touch, 3 you can hear, 2 you can smell, and 1 you can taste.\",\n    \"body_scan\": \"Focus on your toes, tense them, then relax. Move slowly up your body to your head.\"\n}\n\nclass Tools:\n    @staticmethod\n    def get_helpline(country_code=\"Global\"):\n        \"\"\"Returns helpline info for a given country code (US, UK, IN, Global).\"\"\"\n        return HELPLINES.get(country_code, HELPLINES[\"Global\"])\n\n    @staticmethod\n    def get_grounding_technique(technique_name):\n        \"\"\"Returns the script for a specific technique.\"\"\"\n        return TECHNIQUES.get(technique_name, \"Take a deep breath and count to ten.\")\n\n    @staticmethod\n    def get_all_techniques():\n        return list(TECHNIQUES.keys())\n"
    },
    "core": {
        "a2a_protocol.py": "\"\"\"\nDefines the data structures for Agent-to-Agent communication.\n\"\"\"\nfrom dataclasses import dataclass, asdict\nfrom typing import List, Optional\n\n@dataclass\nclass PlannerOutput:\n    emotion: str\n    risk_level: str\n    action: str\n    instruction: str\n\n    def to_dict(self):\n        return asdict(self)\n\n@dataclass\nclass WorkerOutput:\n    draft_response: str\n    tools_used: List[str]\n\n    def to_dict(self):\n        return asdict(self)\n\n@dataclass\nclass EvaluatorOutput:\n    status: str\n    feedback: str\n    final_response: str\n\n    def to_dict(self):\n        return asdict(self)\n",
        "observability.py": "\"\"\"\nSimple logger to track agent thoughts.\n\"\"\"\nimport datetime\n\nclass Logger:\n    def __init__(self):\n        self.logs = []\n\n    def log(self, agent_name, message, data=None):\n        timestamp = datetime.datetime.now().strftime(\"%H:%M:%S\")\n        entry = f\"[{timestamp}] {agent_name}: {message}\"\n        if data:\n            entry += f\"\\nData: {data}\"\n        print(entry) # Print to console for Colab visibility\n        self.logs.append(entry)\n\n    def get_logs(self):\n        return \"\\n\".join(self.logs)\n\n# Singleton instance\nlogger = Logger()\n",
        "context_engineering.py": "\"\"\"\nDefines the system prompts (personas) for the agents.\n\"\"\"\n\nPLANNER_PROMPT = \"\"\"\nYou are an empathetic Mental Health Triage Planner.\nYour goal is to analyze the user's input and conversation history to decide the safest and most helpful course of action.\n\nYou must output a JSON object with the following fields:\n- \"emotion\": The detected emotional state (e.g., anxiety, sadness, anger, neutral).\n- \"risk_level\": \"LOW\", \"MEDIUM\", or \"HIGH\".\n    - HIGH risk includes self-harm, suicide, violence, or immediate medical emergencies.\n- \"action\": The specific action to take. Options:\n    - \"provide_grounding\": If the user is overwhelmed/anxious.\n    - \"provide_resources\": If the user asks for help lines.\n    - \"emergency_protocol\": If risk is HIGH.\n    - \"chat\": For general supportive conversation.\n- \"instruction\": Specific instructions for the Worker agent on what to generate.\n\nExample Input: \"I can't breathe, I'm so stressed about my test.\"\nExample Output:\n{\n    \"emotion\": \"anxiety\",\n    \"risk_level\": \"LOW\",\n    \"action\": \"provide_grounding\",\n    \"instruction\": \"Guide the user through a Box Breathing exercise. Be calm and pacing.\"\n}\n\"\"\"\n\nWORKER_PROMPT = \"\"\"\nYou are a supportive Mental Health Companion (Worker).\nYou are NOT a doctor. You do not diagnose or prescribe.\nYour goal is to generate a response based strictly on the Planner's instructions.\n\nGuidelines:\n- Use warm, simple, non-clinical language.\n- If instructed to provide grounding, use the specific technique provided.\n- If instructed to provide resources, list the relevant helplines.\n- Never make medical claims.\n- If the instruction is 'emergency_protocol', output the standard emergency disclaimer strictly.\n\"\"\"\n\nEVALUATOR_PROMPT = \"\"\"\nYou are a Safety Evaluator.\nYour job is to review the draft response from the Worker agent.\n\nCheck for:\n1. Medical Advice: Does it suggest medication or diagnosis? (FAIL)\n2. Harmful Content: Does it encourage self-harm? (FAIL)\n3. Tone: Is it respectful and safe? (PASS)\n4. Hallucinations: Does it invent fake phone numbers? (FAIL - ensure placeholders or tool outputs are used)\n\nOutput a JSON object:\n{\n    \"status\": \"APPROVED\" or \"REJECTED\",\n    \"feedback\": \"Reason for rejection or empty if approved.\",\n    \"sanitized_response\": \"The response to show the user (if approved, copy draft; if rejected, provide a safety fallback).\"\n}\n\"\"\"\n"
    },
    "memory": {
        "session_memory.py": "\"\"\"\nManages the short-term conversation history.\n\"\"\"\n\nclass SessionMemory:\n    def __init__(self):\n        self.history = [] # List of {\"role\": \"user/assistant\", \"content\": \"...\"}\n\n    def add_message(self, role, content):\n        self.history.append({\"role\": role, \"content\": content})\n\n    def get_history_string(self):\n        \"\"\"Returns history formatted for LLM context.\"\"\"\n        return \"\\n\".join([f\"{msg['role'].upper()}: {msg['content']}\" for msg in self.history])\n\n    def clear(self):\n        self.history = []\n"
    },
    "requirements.txt": "google-generativeai\npython-dotenv\n",
    "code.py": "import os\nimport json\n\nIGNORE_DIRS = {'.git', '__pycache__', 'venv', 'node_modules', 'cache', 'images','.vscode','drive-mad','code.py'}\n\nIGNORE_EXTENSIONS = {'.png', '.jpg', '.jpeg', '.gif', '.bmp', '.ico', '.exe', '.dll', '.gitignore'}\nALWAYS_TEXT_FILES = {'.md'}\n\ndef read_file(file_path):\n    \"\"\"Try reading a file with UTF-8 first, then UTF-16 as fallback.\"\"\"\n    try:\n        with open(file_path, 'r', encoding='utf-8') as f:\n            return f.read()\n    except UnicodeDecodeError:\n        try:\n            with open(file_path, 'r', encoding='utf-16') as f:\n                return f.read()\n        except Exception:\n            return \"<could not read file>\"\n\ndef read_directory(path):\n    result = {}\n    for entry in os.scandir(path):\n        if entry.is_dir():\n            if entry.name in IGNORE_DIRS:\n                continue\n            result[entry.name] = read_directory(entry.path)\n        elif entry.is_file():\n            if any(entry.name.lower().endswith(ext) for ext in IGNORE_EXTENSIONS):\n                continue\n            _, ext = os.path.splitext(entry.name)\n            if ext.lower() in ALWAYS_TEXT_FILES or True:\n                result[entry.name] = read_file(entry.path)\n    return result\n\nroot_dir = '.'  # current directory\n\ndirectory_structure = read_directory(root_dir)\n\nwith open('directory_structure.json', 'w', encoding='utf-8') as f:\n    json.dump(directory_structure, f, ensure_ascii=False, indent=4)\n\nprint(\"Directory structure saved to 'directory_structure.json'\")",
    "agents": {
        "worker.py": "\"\"\"\nWorker Agent: Executes the plan and generates content.\n\"\"\"\nimport os\nimport google.generativeai as genai\nfrom project.core.context_engineering import WORKER_PROMPT\nfrom project.core.a2a_protocol import WorkerOutput\nfrom project.tools.tools import Tools\nfrom project.core.observability import logger\n\nclass Worker:\n    def __init__(self):\n        self.mock_mode = os.environ.get(\"MOCK_MODE\") == \"True\"\n        if not self.mock_mode:\n            genai.configure(api_key=os.environ[\"GOOGLE_API_KEY\"])\n            self.model = genai.GenerativeModel('gemini-1.5-flash')\n\n    def work(self, planner_output):\n        logger.log(\"Worker\", f\"Executing instruction: {planner_output.get('instruction')}\")\n\n        instruction = planner_output.get(\"instruction\", \"\")\n        action = planner_output.get(\"action\", \"\")\n\n        # Tool Usage\n        context_data = \"\"\n        tools_used = []\n\n        if action == \"provide_grounding\":\n            # Simple keyword matching to pick tool\n            if \"box\" in instruction.lower():\n                context_data = Tools.get_grounding_technique(\"box_breathing\")\n                tools_used.append(\"box_breathing\")\n            else:\n                context_data = Tools.get_grounding_technique(\"54321_grounding\")\n                tools_used.append(\"54321_grounding\")\n        elif action == \"provide_resources\":\n            context_data = str(Tools.get_helpline(\"Global\"))\n            tools_used.append(\"helpline_search\")\n\n        if self.mock_mode:\n             draft = f\"[Mock Worker] Based on {action}: {instruction}. Data: {context_data}\"\n             return WorkerOutput(draft, tools_used).to_dict()\n\n        # Real LLM Generation\n        prompt = f\"{WORKER_PROMPT}\\n\\nINSTRUCTION: {instruction}\\nCONTEXT DATA: {context_data}\\n\\nDRAFT RESPONSE:\"\n        response = self.model.generate_content(prompt)\n        return WorkerOutput(response.text, tools_used).to_dict()\n",
        "planner.py": "\"\"\"\nPlanner Agent: Analyzes user input and creates a plan.\n\"\"\"\nimport os\nimport json\nimport google.generativeai as genai\nfrom project.core.context_engineering import PLANNER_PROMPT\nfrom project.core.a2a_protocol import PlannerOutput\nfrom project.core.observability import logger\n\nclass Planner:\n    def __init__(self):\n        self.mock_mode = os.environ.get(\"MOCK_MODE\") == \"True\"\n        if not self.mock_mode:\n            genai.configure(api_key=os.environ[\"GOOGLE_API_KEY\"])\n            self.model = genai.GenerativeModel('gemini-1.5-flash')\n\n    def plan(self, user_input, history_str):\n        logger.log(\"Planner\", \"Analyzing input...\")\n\n        if self.mock_mode:\n            # Simple keyword-based mock logic\n            if \"kill\" in user_input.lower() or \"die\" in user_input.lower():\n                 return PlannerOutput(\"crisis\", \"HIGH\", \"emergency_protocol\", \"Provide emergency disclaimer immediately.\").to_dict()\n            elif \"anxious\" in user_input or \"stress\" in user_input:\n                 return PlannerOutput(\"anxiety\", \"LOW\", \"provide_grounding\", \"Guide user through box_breathing.\").to_dict()\n            else:\n                 return PlannerOutput(\"neutral\", \"LOW\", \"chat\", \"Respond politely.\").to_dict()\n\n        # Real LLM Call\n        prompt = f\"{PLANNER_PROMPT}\\n\\nHISTORY:\\n{history_str}\\n\\nCURRENT INPUT: {user_input}\\n\\nOUTPUT JSON:\"\n        try:\n            response = self.model.generate_content(prompt)\n            # Clean response to ensure valid JSON\n            text = response.text.strip()\n            if text.startswith(\"```json\"): text = text[7:-3]\n            data = json.loads(text)\n            return data\n        except Exception as e:\n            logger.log(\"Planner\", f\"Error: {e}\")\n            return PlannerOutput(\"error\", \"LOW\", \"chat\", \"Apologize and ask again.\").to_dict()\n",
        "evaluator.py": "\"\"\"\nEvaluator Agent: Safety checks.\n\"\"\"\nimport os\nimport json\nimport google.generativeai as genai\nfrom project.core.context_engineering import EVALUATOR_PROMPT\nfrom project.core.a2a_protocol import EvaluatorOutput\nfrom project.core.observability import logger\n\nclass Evaluator:\n    def __init__(self):\n        self.mock_mode = os.environ.get(\"MOCK_MODE\") == \"True\"\n        if not self.mock_mode:\n            genai.configure(api_key=os.environ[\"GOOGLE_API_KEY\"])\n            self.model = genai.GenerativeModel('gemini-1.5-flash')\n\n    def evaluate(self, worker_output):\n        draft = worker_output.get(\"draft_response\")\n        logger.log(\"Evaluator\", \"Checking draft...\")\n\n        if self.mock_mode:\n            return EvaluatorOutput(\"APPROVED\", \"Mock Safe\", draft).to_dict()\n\n        prompt = f\"{EVALUATOR_PROMPT}\\n\\nDRAFT RESPONSE: {draft}\\n\\nOUTPUT JSON:\"\n        try:\n            response = self.model.generate_content(prompt)\n            text = response.text.strip()\n            if text.startswith(\"```json\"): text = text[7:-3]\n            data = json.loads(text)\n\n            # Fallback if json parsing is sloppy\n            final_res = data.get(\"sanitized_response\", draft)\n            if data.get(\"status\") != \"APPROVED\":\n                 final_res = \"I apologize, but I cannot provide that specific advice. However, I am here to listen.\"\n\n            return EvaluatorOutput(data.get(\"status\"), data.get(\"feedback\"), final_res).to_dict()\n        except Exception as e:\n            logger.log(\"Evaluator\", f\"Error: {e}\")\n            return EvaluatorOutput(\"APPROVED\", \"Error skipped\", draft).to_dict()\n"
    },
    "README.md": "# kaggle-capstone-ai-agent\n",
    "main_agent.py": "\"\"\"\nMain Agent: Orchestrator.\n\"\"\"\nfrom project.agents.planner import Planner\nfrom project.agents.worker import Worker\nfrom project.agents.evaluator import Evaluator\nfrom project.memory.session_memory import SessionMemory\nfrom project.core.observability import logger\n\nclass MainAgent:\n    def __init__(self):\n        self.planner = Planner()\n        self.worker = Worker()\n        self.evaluator = Evaluator()\n        self.memory = SessionMemory()\n\n    def handle_message(self, user_input):\n        logger.log(\"System\", f\"User Input: {user_input}\")\n\n        # 1. Update Memory\n        self.memory.add_message(\"user\", user_input)\n        history_str = self.memory.get_history_string()\n\n        # 2. Planner\n        plan = self.planner.plan(user_input, history_str)\n\n        # 3. Worker\n        worker_res = self.worker.work(plan)\n\n        # 4. Evaluator\n        eval_res = self.evaluator.evaluate(worker_res)\n\n        final_response = eval_res.get(\"final_response\")\n\n        # 5. Update Memory\n        self.memory.add_message(\"assistant\", final_response)\n\n        return {\n            \"response\": final_response,\n            \"plan\": plan,\n            \"logs\": logger.get_logs()\n        }\n\ndef run_agent(user_input: str):\n    agent = MainAgent()\n    result = agent.handle_message(user_input)\n    return result[\"response\"]\n",
    "app.py": "\"\"\"\nBasic entry point for an application wrapper.\n\"\"\"\nfrom project.main_agent import run_agent\n\ndef main():\n    print(\"--- Mental Health Companion (Console App) ---\")\n    print(\"Type 'quit' to exit.\")\n\n    while True:\n        user_in = input(\"You: \")\n        if user_in.lower() in [\"quit\", \"exit\"]:\n            break\n\n        response = run_agent(user_in)\n        print(f\"Agent: {response}\")\n\nif __name__ == \"__main__\":\n    main()\n"
}